{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dask-and-TensorFlow-Solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkdPnJDOif7V"
      },
      "source": [
        "# Dask with TensorFlow Assignment\r\n",
        "\r\n",
        "The following assignment is based on [Keras and Tensorflow Dask Example](https://ml.dask.org/keras.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LEyz7kPiW3f"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSpWqODhgiVT"
      },
      "source": [
        "# Dask requires msgpack<1.0 so we will install that first\r\n",
        "!pip install msgpack==0.6.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVvvvS_EjzI-"
      },
      "source": [
        "# We would also need to install dask-ml to run ML algorithms from Dask\r\n",
        "!pip install dask-ml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6osFSiZMgpT3"
      },
      "source": [
        "!pip install dask distributed --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtdBc_wCiuBW"
      },
      "source": [
        "# The package SciKeras brings a Scikit-learn API to Keras. This allows Dask-ML to be used seamlessly with Keras models.\r\n",
        "!pip install scikeras>=0.1.8"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjTBe6Vk_OyH"
      },
      "source": [
        "After running all three, make sure you restart the kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DPbTUMoiVhV"
      },
      "source": [
        "## Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p98UnHxaiYKg"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Dense, Flatten\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "\r\n",
        "def build_model(beta_1=0.9):\r\n",
        "    # build a model with:\r\n",
        "    # Flatten layer with size (28, 28)\r\n",
        "    # Dense layer with 128 and relu activation \r\n",
        "    # Dense layer with 10 and softmax activation\r\n",
        "    layers = [Flatten(input_shape=(28, 28)),\r\n",
        "              Dense(128, activation='relu'),\r\n",
        "              Dense(10, activation=\"softmax\")]\r\n",
        "    model = Sequential(layers)\r\n",
        "\r\n",
        "    # Use Adam Optimizer and pass in the beta_1 variable\r\n",
        "    # If you would like to add more parameters, make sure you modify the function parameters\r\n",
        "    opt = tf.keras.optimizers.Adam(beta_1=beta_1)\r\n",
        "    # Use SparseCategoricalCrossentropy as your loss function with from_logits as True \r\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "    # Compile the model with accuracy metric\r\n",
        "    model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "    return model"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBzchGjiibrK"
      },
      "source": [
        "Now, we can use the SciKeras to create a Scikit-learn compatible model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sPCmX-Gid92"
      },
      "source": [
        "from scikeras.wrappers import KerasClassifier\r\n",
        "niceties = dict(verbose=False)\r\n",
        "model = KerasClassifier(build_fn=build_model, beta_1=0.9, **niceties)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alOH84O0iys6"
      },
      "source": [
        "This model will work with all of Dask-ML: it can use NumPy arrays as inputs and obeys the Scikit-learn API. For example, it’s possible to use Dask-ML to do the following:\r\n",
        "- Use Keras with Dask-ML’s model selection, including `HyperbandSearchCV`.\r\n",
        "- Use Keras with Dask-ML’s `Incremental`.\r\n",
        "\r\n",
        "If we want to tune `learning_rate`, `beta_1` and `beta_2`, SciKeras requires that we pass `learning_rate`, `beta_1` and `beta_2` at initialization:\r\n",
        "\r\n",
        "SciKeras supports more model creation methods, including some that are backwards-compatible with Tensorflow. Refer to their documentation for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cVYR740jAPO"
      },
      "source": [
        "## Hyperparameter Optimization\r\n",
        "\r\n",
        "If we wanted to, we could use the model above with `HyperbandSearchCV`. Let’s tune this model on the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ggCffFkjFy6"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "import numpy as np\r\n",
        "from typing import Tuple\r\n",
        "\r\n",
        "def get_mnist() -> Tuple[np.ndarray, np.ndarray]:\r\n",
        "    (X_train, y_train), _ = mnist.load_data()\r\n",
        "    X_train = X_train.astype(\"float32\")\r\n",
        "    X_train /= 255\r\n",
        "    return X_train, y_train"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQcE2UQMjHP8"
      },
      "source": [
        "And let’s perform the basic task of tuning our Adam implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKZdA7AijJew"
      },
      "source": [
        "params = {\"beta_1\": [0.7, 0.8, 0.9]}\r\n",
        "X, y = get_mnist()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Err-Yd2kjKmq"
      },
      "source": [
        "Now, the search can be run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX0LEoP7jMXH",
        "outputId": "17fa4400-99ef-4aed-8753-0f3f11250af0"
      },
      "source": [
        "from dask.distributed import Client\r\n",
        "client = Client()\r\n",
        "\r\n",
        "from dask_ml.model_selection import HyperbandSearchCV\r\n",
        "\r\n",
        "# Run HyperbandSearchCV with model, params and max_iter as 3\r\n",
        "# If you run a larger iteration or more parameters, you may run into issues depending on \r\n",
        "# how much compute power you have access to.\r\n",
        "search = HyperbandSearchCV(model, params, max_iter=3)\r\n",
        "search.fit(X, y)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
            "Perhaps you already have a cluster running?\n",
            "Hosting the HTTP server on port 33183 instead\n",
            "  http_address[\"port\"], self.http_server.port\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HyperbandSearchCV(estimator=KerasClassifier(beta_1=0.9, build_fn=<function build_model at 0x7f47c93a60d0>, verbose=False),\n",
              "                  max_iter=3, parameters={'beta_1': [0.7, 0.8, 0.9]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QM-el7VyzFV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}